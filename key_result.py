# -*- coding: utf-8 -*-
"""Key_Result.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X4CNlyEKhCzN9KaW8_OhUIff9i4GC3UO
"""

import torch
import torch.nn as nn
import numpy as np
from transformers import BertModel, BertTokenizer

class LatentRefiner(nn.Module):
    def __init__(self):
        super(LatentRefiner, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(32 * 32 * 32, 128)
        self.fc2 = nn.Linear(128, 32 * 32)
        self.relu = nn.ReLU()

    def forward(self, x):
        batch_size = x.size(0)
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = x.view(batch_size, -1)
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        x = x.view(batch_size, 1, 32, 32)
        return x

def embed_prompt(prompt):
    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
    model = BertModel.from_pretrained('bert-base-uncased')
    inputs = tokenizer(prompt, return_tensors="pt", padding=True, truncation=True, max_length=512)
    outputs = model(**inputs)
    prompt_embedding = outputs.last_hidden_state.mean(dim=1)
    return prompt_embedding

def process_latent(latent):
    return torch.tanh(latent)  # Transform using hyperbolic tangent.

def feedback_process(prompt, initial_noise, iterations):
    prompt_embedding = embed_prompt(prompt)
    prompt_embedding_resized = torch.tensor(np.resize(prompt_embedding.detach().numpy(), (1, 1, 32, 32)), dtype=torch.float32)
    current_latent = initial_noise + prompt_embedding_resized

    for _ in range(iterations):
        current_latent = process_latent(current_latent)

    return current_latent

initial_noise = torch.rand(1, 1, 32, 32)  # Ensure the initial noise is a 4D tensor
refined_latent = feedback_process("Chaitaalllllll", initial_noise, 100)
refiner = LatentRefiner()
refined_output = refiner(refined_latent)

print(refined_output.shape)

print(refined_output)

from skimage.feature import hog
refined_matrix_np = refined_output.squeeze().detach().numpy()
hog_features, hog_image = hog(refined_matrix_np, visualize=True, block_norm='L2-Hys')

print("HOG Features Shape:", hog_features.shape)

import matplotlib.pyplot as plt
plt.imshow(hog_image, cmap='gray')
plt.title("HOG Image")
plt.show()

hog_features = hog_features.reshape(1, 1, -1)
conv_layer = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1, bias=False)
hog_features_tensor = torch.tensor(hog_features, dtype=torch.float32)
key_tensor = conv_layer(hog_features_tensor)
key = key_tensor.detach().numpy()

print("Generated Key:", key)

class VAE_Decoder(nn.Module):
    def __init__(self, latent_dim):
        super(VAE_Decoder, self).__init__()

        self.latent_dim = latent_dim

        # Define the decoder network
        self.fc = nn.Linear(latent_dim, 32 * 32)  # Output size is 32x32
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(in_channels=1, out_channels=32, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(in_channels=16, out_channels=1, kernel_size=3, stride=1, padding=1),
            nn.Sigmoid()  # Sigmoid activation to output pixel values in [0, 1]
        )

    def forward(self, z):
        # Fully connected layer to map latent vector to decoder input size
        x = self.fc(z)
        x = x.view(-1, 1, 32, 32)  # Reshape to match convolutional layer input shape
        x = self.decoder(x)
        return x

latent_dim = 32  # Assuming latent dimension
vae_decoder = VAE_Decoder(latent_dim)

final_image = vae_decoder(refined_output)

print("Final Image Shape:", final_image.shape)

final_image_np = final_image.squeeze().detach().numpy()

plt.imshow(final_image_np[10], cmap='gray')
plt.title('Reconstructed Image')
plt.axis('off')
plt.show()

prompt_to_key = {"Chaitaalllllll": key}

print(prompt_to_key)

